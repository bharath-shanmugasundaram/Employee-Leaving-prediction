# ğŸ§  Employee Attrition Prediction â€” Deep Neural Network (PyTorch)

This project builds a **Deep Learning model** using PyTorch to predict **employee attrition** (whether an employee will leave a company).  
The project includes:

- Full dataset preprocessing  
- Feature encoding & normalization  
- Deep Neural Network with multiple layers  
- Dropout regularization  
- L2 weight decay regularization  
- Training/Dev/Test split  
- Multiple experiment comparisons  
- Final accuracy evaluation  

This is an end-to-end HR analytics project demonstrating how to use structured data with neural networks.

---

## ğŸ“‚ Dataset

The model uses the dataset:
HR-Employee-Attrition.csv


Target column:

| Column | Description |
|--------|-------------|
| `Attrition` | 1 = Employee Left, 0 = Employee Stayed |

Categorical columns (BusinessTravel, Department, Gender, JobRole, etc.) are converted into numerical encoded versions.

---

## ğŸ§¹ Data Preprocessing

### 1ï¸âƒ£ Convert target variable to numerical
```python
df["Attrition"] = df["Attrition"].map({"Yes": 1, "No": 0})
2ï¸âƒ£ Encode categorical variables
Example:

df["BusinessTravel"] = df["BusinessTravel"].map({
    'Travel_Rarely': 1,
    'Travel_Frequently': 2,
    'Non-Travel': 0
})
Multiple columns are encoded similarly:

Department
EducationField
Gender
JobRole
MaritalStatus
Over18
OverTime
3ï¸âƒ£ Split features + labels
Y = df["Attrition"].to_numpy(dtype=np.float32)
df = df.drop("Attrition", axis=1)
X = df.to_numpy(dtype=np.float32)
4ï¸âƒ£ Standardization
scaler = StandardScaler()
X = scaler.fit_transform(X)
5ï¸âƒ£ Train/Dev/Test Split
70% â€” Train  
15% â€” Dev  
15% â€” Test
X_train, X_test, Y_train, Y_test = train_test_split(...)
X_test, X_dev, Y_test, Y_dev = train_test_split(...)
ğŸ§  Neural Network Architecture
A deep fully connected neural network:

Input â†’ 64 â†’ 32 â†’ 16 â†’ 8 â†’ 4 â†’ Output(1)
ReLU activation + Dropout(0.3)
class Neural(nn.Module):
    def __init__(self, input_size):
        super(Neural, self).__init__()
        self.net = nn.Sequential(
            nn.Linear(input_size, 64),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(32, 16),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(16, 8),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(8, 4),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(4, 1)
        )
Loss & Optimizer
criterion = nn.BCEWithLogitsLoss()
optimizer = optim.Adam(model.parameters(), lr=0.01)
ğŸ” Training Loop
1000 training epochs
Tracks training & dev accuracy every 10 epochs
y_pred = model(X_train)
loss = criterion(y_pred, Y_train)

loss.backward()
optimizer.step()
optimizer.zero_grad()
ğŸ“Š Model Evaluation
On Test Set
with torch.no_grad():
    y_test_pred = model(X_test)
    y_test_class = (torch.sigmoid(y_test_pred) >= 0.5).float()
    test_acc = (y_test_class.eq(Y_test).sum() / Y_test.shape[0]) * 100
ğŸ§ª Experiments & Results
You ran the model with different regularization strategies.
1ï¸âƒ£ No Regularization
Train Accuracy: 100.00%
Dev Accuracy:   84.62%
Test Accuracy:  83.64%
2ï¸âƒ£ Dropout Regularization (0.3)
Train Accuracy: 96.99%
Dev Accuracy:   81.90%
Test Accuracy:  87.27%
ğŸ“ˆ Best Test Accuracy: 87.27%
3ï¸âƒ£ Dropout + L2 Regularization
Train Accuracy: 82.90%
Dev Accuracy:   86.88%
Test Accuracy:  85.45%
4ï¸âƒ£ L2 Regularization Only
Train Accuracy: 99.61%
Dev Accuracy:   85.52%
Test Accuracy:  85.00%
ğŸ“Œ Best-performing model
â­ Dropout Regularization (0.3)
Test Accuracy = **87.27%**
This model generalizes the best.
ğŸ“ˆ Loss Curve Visualization
Loss plotted using seaborn:

sns.lineplot(cost)
ğŸ Summary
This project demonstrates:
âœ” End-to-end preprocessing of HR attrition dataset
âœ” Encoding categorical features
âœ” Standardization using StandardScaler
âœ” Deep neural network built using PyTorch
âœ” Comparison of multiple regularization techniques
âœ” Proper Train/Dev/Test evaluation
âœ” Achieving 87% accuracy on real employee attrition data
Itâ€™s a solid example of tabular deep learning using PyTorch.
â­ If you like this project
Please give the repository a star â­ on GitHub!
Need help generating:

model.py
train.py
predict.py
inference notebook
Folder structure
Just tell me!

